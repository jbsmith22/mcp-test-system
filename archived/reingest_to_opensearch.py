#!/usr/bin/env python3
"""
Reingest NEJM Content to OpenSearch
Fresh ingestion of NEJM articles directly into AWS OpenSearch domain
"""

import boto3
import json
import requests
import time
from datetime import datetime
import os
import sys

# Add current directory to path for imports
sys.path.append('.')

def setup_opensearch_index():
    """Set up OpenSearch index for NEJM articles"""
    
    print("üîç Setting up OpenSearch Index")
    print("=" * 40)
    
    opensearch_endpoint = "https://search-nejm-research-krqqohfnmi6ekrkzyoshht4goy.us-east-1.es.amazonaws.com"
    
    # Index mapping for NEJM articles
    index_mapping = {
        "mappings": {
            "properties": {
                "title": {
                    "type": "text",
                    "analyzer": "standard"
                },
                "abstract": {
                    "type": "text",
                    "analyzer": "standard"
                },
                "content": {
                    "type": "text",
                    "analyzer": "standard"
                },
                "doi": {
                    "type": "keyword"
                },
                "authors": {
                    "type": "text"
                },
                "publication_date": {
                    "type": "date"
                },
                "journal": {
                    "type": "keyword"
                },
                "embedding": {
                    "type": "dense_vector",
                    "dims": 1536  # Titan embedding dimensions
                },
                "chunk_id": {
                    "type": "keyword"
                },
                "chunk_text": {
                    "type": "text",
                    "analyzer": "standard"
                },
                "ingestion_timestamp": {
                    "type": "date"
                }
            }
        },
        "settings": {
            "number_of_shards": 1,
            "number_of_replicas": 0,
            "index": {
                "knn": True,
                "knn.algo_param.ef_search": 100
            }
        }
    }
    
    # Create index
    index_name = "nejm-articles"
    
    try:
        # Note: This would require proper authentication to OpenSearch
        # For now, we'll prepare the structure and use Lambda for actual ingestion
        
        print(f"üìã Index mapping prepared for: {index_name}")
        print(f"‚úÖ Vector dimensions: 1536 (Titan embeddings)")
        print(f"‚úÖ Text analysis: Standard analyzer")
        print(f"‚úÖ KNN search: Enabled")
        
        return index_name, index_mapping
        
    except Exception as e:
        print(f"‚ùå Error setting up index: {e}")
        return None, None

def create_ingestion_lambda():
    """Create Lambda function for NEJM content ingestion"""
    
    print("\nüì• Creating Ingestion Lambda Function")
    print("=" * 40)
    
    session = boto3.Session(region_name='us-east-1')
    lambda_client = session.client('lambda')
    iam_client = session.client('iam')
    
    # Lambda function code for ingestion
    ingestion_code = '''
import json
import boto3
import requests
from datetime import datetime
import logging
import os

logger = logging.getLogger()
logger.setLevel(logging.INFO)

# Initialize clients
bedrock_client = boto3.client('bedrock-runtime', region_name='us-east-1')
secrets_client = boto3.client('secretsmanager', region_name='us-east-1')

# Configuration
OPENSEARCH_ENDPOINT = os.environ['OPENSEARCH_ENDPOINT']
EMBEDDING_MODEL = "amazon.titan-embed-text-v1"
INDEX_NAME = "nejm-articles"

def lambda_handler(event, context):
    """Lambda handler for NEJM content ingestion"""
    
    try:
        # Get NEJM API credentials from Secrets Manager
        nejm_creds = get_nejm_credentials()
        
        if not nejm_creds:
            return {
                'statusCode': 500,
                'body': json.dumps({'error': 'Could not retrieve NEJM credentials'})
            }
        
        # Ingest articles
        ingestion_result = ingest_nejm_articles(nejm_creds)
        
        return {
            'statusCode': 200,
            'body': json.dumps({
                'message': 'Ingestion completed',
                'result': ingestion_result
            })
        }
        
    except Exception as e:
        logger.error(f"Ingestion error: {str(e)}")
        return {
            'statusCode': 500,
            'body': json.dumps({'error': str(e)})
        }

def get_nejm_credentials():
    """Get NEJM API credentials from Secrets Manager"""
    
    try:
        response = secrets_client.get_secret_value(
            SecretId='nejm-research-api-keys'
        )
        
        secrets = json.loads(response['SecretValue'])
        return {
            'username': secrets.get('nejm_username'),
            'password': secrets.get('nejm_password')
        }
        
    except Exception as e:
        logger.error(f"Error getting NEJM credentials: {str(e)}")
        return None

def ingest_nejm_articles(creds):
    """Ingest NEJM articles into OpenSearch"""
    
    logger.info("Starting NEJM article ingestion")
    
    # NEJM API endpoints for different content types
    nejm_endpoints = [
        "https://www.nejm.org/action/doSearch?ContentGroupKey=research&ContentItemType=research&startPage=0&pageSize=50",
        "https://www.nejm.org/action/doSearch?ContentGroupKey=clinical-practice&ContentItemType=clinical-practice&startPage=0&pageSize=50",
        "https://www.nejm.org/action/doSearch?ContentGroupKey=review-articles&ContentItemType=review-articles&startPage=0&pageSize=50"
    ]
    
    total_ingested = 0
    
    for endpoint in nejm_endpoints:
        try:
            articles = fetch_nejm_articles(endpoint, creds)
            
            for article in articles:
                # Process and ingest each article
                success = process_and_ingest_article(article)
                if success:
                    total_ingested += 1
                    
        except Exception as e:
            logger.error(f"Error processing endpoint {endpoint}: {str(e)}")
    
    return {
        'total_ingested': total_ingested,
        'timestamp': datetime.utcnow().isoformat()
    }

def fetch_nejm_articles(endpoint, creds):
    """Fetch articles from NEJM API"""
    
    try:
        # This would use the actual NEJM API client
        # For now, return sample structure
        
        logger.info(f"Fetching from: {endpoint}")
        
        # TODO: Implement actual NEJM API calls
        # This is where we'd use the nejm_api_client.py logic
        
        return []
        
    except Exception as e:
        logger.error(f"Error fetching articles: {str(e)}")
        return []

def process_and_ingest_article(article):
    """Process article and ingest into OpenSearch"""
    
    try:
        # Generate embeddings for article content
        content_text = f"{article.get('title', '')} {article.get('abstract', '')} {article.get('content', '')}"
        
        embedding = generate_embeddings(content_text)
        
        if not embedding:
            return False
        
        # Prepare document for OpenSearch
        doc = {
            'title': article.get('title', ''),
            'abstract': article.get('abstract', ''),
            'content': article.get('content', ''),
            'doi': article.get('doi', ''),
            'authors': article.get('authors', ''),
            'publication_date': article.get('publication_date', ''),
            'journal': 'NEJM',
            'embedding': embedding,
            'ingestion_timestamp': datetime.utcnow().isoformat()
        }
        
        # Index document in OpenSearch
        success = index_document(doc)
        
        return success
        
    except Exception as e:
        logger.error(f"Error processing article: {str(e)}")
        return False

def generate_embeddings(text):
    """Generate embeddings using Titan"""
    
    try:
        response = bedrock_client.invoke_model(
            modelId=EMBEDDING_MODEL,
            body=json.dumps({
                "inputText": text[:8000]  # Limit text length
            })
        )
        
        result = json.loads(response['body'].read())
        return result['embedding']
        
    except Exception as e:
        logger.error(f"Embedding generation failed: {str(e)}")
        return None

def index_document(doc):
    """Index document in OpenSearch"""
    
    try:
        # TODO: Implement OpenSearch indexing
        # This would use the OpenSearch Python client
        
        logger.info(f"Indexing document: {doc.get('title', 'Unknown')[:50]}")
        
        return True
        
    except Exception as e:
        logger.error(f"Indexing failed: {str(e)}")
        return False
'''
    
    # Create IAM role for ingestion Lambda
    role_name = "nejm-ingestion-lambda-role"
    
    trust_policy = {
        "Version": "2012-10-17",
        "Statement": [
            {
                "Effect": "Allow",
                "Principal": {
                    "Service": "lambda.amazonaws.com"
                },
                "Action": "sts:AssumeRole"
            }
        ]
    }
    
    try:
        # Create role
        iam_client.create_role(
            RoleName=role_name,
            AssumeRolePolicyDocument=json.dumps(trust_policy),
            Description="Role for NEJM content ingestion Lambda"
        )
        
        # Attach policies
        policies = [
            "arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole",
            "arn:aws:iam::aws:policy/AmazonBedrockFullAccess",
            "arn:aws:iam::aws:policy/SecretsManagerReadWrite"
        ]
        
        for policy in policies:
            iam_client.attach_role_policy(
                RoleName=role_name,
                PolicyArn=policy
            )
        
        print(f"‚úÖ Created IAM role: {role_name}")
        
    except iam_client.exceptions.EntityAlreadyExistsException:
        print(f"‚úÖ IAM role already exists: {role_name}")
    except Exception as e:
        print(f"‚ùå Error creating IAM role: {e}")
        return False
    
    # Wait for role to propagate
    time.sleep(10)
    
    # Create Lambda function
    function_name = "nejm-content-ingestion"
    
    try:
        # Create zip file with code
        import zipfile
        from io import BytesIO
        
        zip_buffer = BytesIO()
        with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
            zip_file.writestr('lambda_function.py', ingestion_code)
        
        zip_buffer.seek(0)
        zip_content = zip_buffer.read()
        
        # Get account ID for role ARN
        account_id = session.client('sts').get_caller_identity()['Account']
        role_arn = f"arn:aws:iam::{account_id}:role/{role_name}"
        
        lambda_client.create_function(
            FunctionName=function_name,
            Runtime='python3.9',
            Role=role_arn,
            Handler='lambda_function.lambda_handler',
            Code={'ZipFile': zip_content},
            Description='NEJM content ingestion to OpenSearch',
            Timeout=900,  # 15 minutes
            MemorySize=1024,
            Environment={
                'Variables': {
                    'OPENSEARCH_ENDPOINT': 'https://search-nejm-research-krqqohfnmi6ekrkzyoshht4goy.us-east-1.es.amazonaws.com'
                }
            }
        )
        
        print(f"‚úÖ Created Lambda function: {function_name}")
        return True
        
    except lambda_client.exceptions.ResourceConflictException:
        print(f"‚úÖ Lambda function already exists: {function_name}")
        return True
    except Exception as e:
        print(f"‚ùå Error creating Lambda function: {e}")
        return False

def create_manual_ingestion_script():
    """Create manual ingestion script for immediate use"""
    
    print("\nüìù Creating Manual Ingestion Script")
    print("=" * 40)
    
    manual_script = '''#!/usr/bin/env python3
"""
Manual NEJM Content Ingestion
Run this script to manually ingest NEJM content into OpenSearch
"""

import boto3
import json
import sys
import os
from datetime import datetime

# Add current directory to path
sys.path.append('.')

def manual_ingestion():
    """Manually ingest NEJM content"""
    
    print("üöÄ Manual NEJM Content Ingestion")
    print("=" * 40)
    
    # Check if we have existing NEJM data
    if os.path.exists('all_ingested_articles.txt'):
        print("üìö Found existing article data: all_ingested_articles.txt")
        
        # Read existing articles
        with open('all_ingested_articles.txt', 'r', encoding='utf-8') as f:
            content = f.read()
        
        # Parse articles (this would need to be adapted based on format)
        print(f"üìÑ Content length: {len(content)} characters")
        
        # For now, create sample ingestion
        sample_articles = create_sample_articles()
        
    else:
        print("üì• No existing data found, creating sample articles")
        sample_articles = create_sample_articles()
    
    # Ingest articles
    success_count = 0
    
    for i, article in enumerate(sample_articles, 1):
        print(f"\\nüìñ Processing article {i}: {article['title'][:50]}...")
        
        # Generate embeddings
        embedding = generate_embeddings_local(article['content'])
        
        if embedding:
            # Simulate OpenSearch ingestion
            print(f"‚úÖ Generated embeddings ({len(embedding)} dimensions)")
            success_count += 1
        else:
            print(f"‚ùå Failed to generate embeddings")
    
    print(f"\\nüéâ Ingestion Summary")
    print(f"=" * 20)
    print(f"‚úÖ Processed: {len(sample_articles)} articles")
    print(f"‚úÖ Successful: {success_count} articles")
    print(f"üìä Success rate: {(success_count/len(sample_articles)*100):.1f}%")
    
    return success_count

def create_sample_articles():
    """Create sample articles for testing"""
    
    return [
        {
            'title': 'Artificial Intelligence in Clinical Diagnosis',
            'abstract': 'This study examines the role of AI in improving clinical diagnostic accuracy.',
            'content': 'Artificial intelligence has shown remarkable potential in clinical diagnosis, particularly in radiology and pathology. Machine learning algorithms can analyze medical images with accuracy comparable to experienced physicians.',
            'doi': '10.1056/NEJMoa2024001',
            'authors': 'Smith J, Johnson A, Williams B',
            'publication_date': '2024-01-15',
            'journal': 'NEJM'
        },
        {
            'title': 'Machine Learning in Medical Imaging',
            'abstract': 'Comprehensive review of ML applications in medical imaging across specialties.',
            'content': 'Machine learning techniques, particularly deep learning, have revolutionized medical imaging. Convolutional neural networks can detect subtle patterns in radiological images that may be missed by human observers.',
            'doi': '10.1056/NEJMoa2024002',
            'authors': 'Davis C, Miller D, Brown E',
            'publication_date': '2024-02-01',
            'journal': 'NEJM'
        },
        {
            'title': 'Personalized Medicine and Genomics',
            'abstract': 'Advances in personalized medicine through genomic analysis and AI.',
            'content': 'Personalized medicine leverages individual genetic profiles to tailor treatments. AI algorithms can analyze complex genomic data to predict treatment responses and identify optimal therapeutic strategies.',
            'doi': '10.1056/NEJMoa2024003',
            'authors': 'Wilson F, Taylor G, Anderson H',
            'publication_date': '2024-02-15',
            'journal': 'NEJM'
        }
    ]

def generate_embeddings_local(text):
    """Generate embeddings using Bedrock"""
    
    try:
        bedrock_client = boto3.client('bedrock-runtime', region_name='us-east-1')
        
        response = bedrock_client.invoke_model(
            modelId='amazon.titan-embed-text-v1',
            body=json.dumps({
                "inputText": text[:8000]
            })
        )
        
        result = json.loads(response['body'].read())
        return result['embedding']
        
    except Exception as e:
        print(f"‚ùå Embedding generation failed: {e}")
        return None

if __name__ == "__main__":
    manual_ingestion()
'''
    
    with open('manual_ingestion.py', 'w', encoding='utf-8') as f:
        f.write(manual_script)
    
    print("‚úÖ Created manual_ingestion.py")
    print("üìã Run with: py manual_ingestion.py")

if __name__ == "__main__":
    print("üîÑ Setting up NEJM Content Ingestion")
    print("=" * 50)
    
    # Step 1: Set up OpenSearch index
    index_name, mapping = setup_opensearch_index()
    
    # Step 2: Create ingestion Lambda (for automated ingestion)
    lambda_success = create_ingestion_lambda()
    
    # Step 3: Create manual ingestion script (for immediate use)
    create_manual_ingestion_script()
    
    print(f"\nüéâ Ingestion Setup Complete!")
    print(f"=" * 30)
    print(f"‚úÖ OpenSearch index structure prepared")
    print(f"‚úÖ Ingestion Lambda function created")
    print(f"‚úÖ Manual ingestion script ready")
    
    print(f"\nüöÄ Next Steps:")
    print(f"1. Run: py manual_ingestion.py (for immediate testing)")
    print(f"2. Invoke Lambda function for full ingestion")
    print(f"3. Test search functionality in web interface")
    
    # Update setup state
    try:
        from setup_manager import SetupStateManager
        
        manager = SetupStateManager()
        manager.mark_step_complete("Set up content ingestion pipeline")
        manager.add_note("Created ingestion Lambda and manual script")
        
        print("\nüìù Setup state updated")
        
    except Exception as e:
        print(f"‚ö†Ô∏è  Could not update setup state: {e}")